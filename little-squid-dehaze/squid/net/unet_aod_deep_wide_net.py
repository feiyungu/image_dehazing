#!/usr/bin/env python3
# -*- coding:utf-8 -*-

# Implementation of AOD-Net in ICCV2017
# Created by Zhao Yuhang in Meitu.

import os 
import torch
import torch.nn as nn
from torch.autograd import Variable

class Unet_AOD_Deep_Wide_Net(nn.Module):
	def __init__(self, feature_nums=64):
		super(Unet_AOD_Deep_Wide_Net, self).__init__()
		self.conv1 = nn.Conv2d(3, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn1 = nn.BatchNorm2d(feature_nums)
		self.relu1 = nn.ReLU(inplace=True)
		self.conv2 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn2 = nn.BatchNorm2d(feature_nums)
		self.relu2 = nn.ReLU(inplace=True)
		self.conv3 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn3 = nn.BatchNorm2d(feature_nums)
		self.relu3 = nn.ReLU(inplace=True)
		self.conv4 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn4 = nn.BatchNorm2d(feature_nums)
		self.relu4 = nn.ReLU(inplace=True)
		self.conv5 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn5 = nn.BatchNorm2d(feature_nums)
		self.relu5 = nn.ReLU(inplace=True)
		self.conv6 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn6 = nn.BatchNorm2d(feature_nums)
		self.relu6 = nn.ReLU(inplace=True)
		self.conv7 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn7 = nn.BatchNorm2d(feature_nums)
		self.relu7 = nn.ReLU(inplace=True)
		self.conv8 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn8 = nn.BatchNorm2d(feature_nums)
		self.relu8 = nn.ReLU(inplace=True)
		self.conv9 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn9 = nn.BatchNorm2d(feature_nums)
		self.relu9 = nn.ReLU(inplace=True)
		self.conv10 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn10 = nn.BatchNorm2d(feature_nums)
		self.relu10 = nn.ReLU(inplace=True)

		self.conv11 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn11 = nn.BatchNorm2d(feature_nums)
		self.relu11 = nn.ReLU(inplace=True)
		self.conv12 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn12 = nn.BatchNorm2d(feature_nums)
		self.relu12 = nn.ReLU(inplace=True)
		self.conv13 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn13 = nn.BatchNorm2d(feature_nums)
		self.relu13 = nn.ReLU(inplace=True)
		self.conv14 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn14 = nn.BatchNorm2d(feature_nums)
		self.relu14 = nn.ReLU(inplace=True)
		self.conv15 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn15 = nn.BatchNorm2d(feature_nums)
		self.relu15 = nn.ReLU(inplace=True)
		self.conv16 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn16 = nn.BatchNorm2d(feature_nums)
		self.relu16 = nn.ReLU(inplace=True)
		self.conv17 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn17 = nn.BatchNorm2d(feature_nums)
		self.relu17 = nn.ReLU(inplace=True)
		self.conv18 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn18 = nn.BatchNorm2d(feature_nums)
		self.relu18 = nn.ReLU(inplace=True)
		self.conv19 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn19 = nn.BatchNorm2d(feature_nums)
		self.relu19 = nn.ReLU(inplace=True)
		self.conv20 = nn.Conv2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn20 = nn.BatchNorm2d(feature_nums)
		self.relu20 = nn.ReLU(inplace=True)

		self.conv21 = nn.ConvTranspose2d(feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn21 = nn.BatchNorm2d(feature_nums)
		self.relu21 = nn.ReLU(inplace=True)
		self.conv22 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn22 = nn.BatchNorm2d(feature_nums)
		self.relu22 = nn.ReLU(inplace=True)
		self.conv23 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn23 = nn.BatchNorm2d(feature_nums)
		self.relu23 = nn.ReLU(inplace=True)
		self.conv24 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn24 = nn.BatchNorm2d(feature_nums)
		self.relu24 = nn.ReLU(inplace=True)
		self.conv25 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn25 = nn.BatchNorm2d(feature_nums)
		self.relu25 = nn.ReLU(inplace=True)
		self.conv26 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn26 = nn.BatchNorm2d(feature_nums)
		self.relu26 = nn.ReLU(inplace=True)
		self.conv27 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn27 = nn.BatchNorm2d(feature_nums)
		self.relu27 = nn.ReLU(inplace=True)
		self.conv28 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn28 = nn.BatchNorm2d(feature_nums)
		self.relu28 = nn.ReLU(inplace=True)
		self.conv29 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn29 = nn.BatchNorm2d(feature_nums)
		self.relu29 = nn.ReLU(inplace=True)
		self.conv30 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn30 = nn.BatchNorm2d(feature_nums)
		self.relu30 = nn.ReLU(inplace=True)

		self.conv31 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn31 = nn.BatchNorm2d(feature_nums)
		self.relu31 = nn.ReLU(inplace=True)
		self.conv32 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn32 = nn.BatchNorm2d(feature_nums)
		self.relu32 = nn.ReLU(inplace=True)
		self.conv33 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn33 = nn.BatchNorm2d(feature_nums)
		self.relu33 = nn.ReLU(inplace=True)
		self.conv34 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn34 = nn.BatchNorm2d(feature_nums)
		self.relu34 = nn.ReLU(inplace=True)
		self.conv35 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn35 = nn.BatchNorm2d(feature_nums)
		self.relu35 = nn.ReLU(inplace=True)
		self.conv36 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn36 = nn.BatchNorm2d(feature_nums)
		self.relu36 = nn.ReLU(inplace=True)
		self.conv37 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn37 = nn.BatchNorm2d(feature_nums)
		self.relu37 = nn.ReLU(inplace=True)
		self.conv38 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn38 = nn.BatchNorm2d(feature_nums)
		self.relu38 = nn.ReLU(inplace=True)
		self.conv39 = nn.ConvTranspose2d(2 * feature_nums, feature_nums, kernel_size=3, stride=1, padding=1)
		self.bn39 = nn.BatchNorm2d(feature_nums)
		self.relu39 = nn.ReLU(inplace=True)
		self.conv40 = nn.ConvTranspose2d(2 * feature_nums, 3, kernel_size=3, stride=1, padding=1)
		self.bn40 = nn.BatchNorm2d(3)
		self.relu40 = nn.ReLU(inplace=True)

		self.clip = nn.ReLU(inplace=True)

	def forward(self, x, target=None):
		x1_0 = x
		x1 = self.conv1(x1_0)
		x1 = self.bn1(x1)
		x1 = self.relu1(x1)
		x2_0 = x1
		x2 = self.conv2(x2_0)
		x2 = self.bn2(x2)
		x2 = self.relu2(x2)
		x3_0 = x2
		x3 = self.conv3(x3_0)
		x3 = self.bn3(x3)
		x3 = self.relu3(x3)
		x4_0 = x3
		x4 = self.conv4(x4_0)
		x4 = self.bn4(x4)
		x4 = self.relu4(x4)
		x5_0 = x4
		x5 = self.conv5(x5_0)
		x5 = self.bn5(x5)
		x5 = self.relu5(x5)
		x6_0 = x5
		x6 = self.conv6(x6_0)
		x6 = self.bn6(x6)
		x6 = self.relu6(x6)
		x7_0 = x6
		x7 = self.conv7(x7_0)
		x7 = self.bn7(x7)
		x7 = self.relu7(x7)
		x8_0 = x7
		x8 = self.conv8(x8_0)
		x8 = self.bn8(x8)
		x8 = self.relu8(x8)
		x9_0 = x8
		x9 = self.conv9(x9_0)
		x9 = self.bn9(x9)
		x9 = self.relu9(x9)
		x10_0 = x9
		x10 = self.conv10(x10_0)
		x10 = self.bn10(x10)
		x10 = self.relu10(x10)
		x11_0 = x10
		x11 = self.conv11(x11_0)
		x11 = self.bn11(x11)
		x11 = self.relu11(x11)

		x12_0 = x11
		x12 = self.conv12(x12_0)
		x12 = self.bn12(x12)
		x12 = self.relu12(x12)
		x13_0 = x12
		x13 = self.conv13(x13_0)
		x13 = self.bn13(x13)
		x13 = self.relu13(x13)
		x14_0 = x13
		x14 = self.conv14(x14_0)
		x14 = self.bn14(x14)
		x14 = self.relu14(x14)
		x15_0 = x14
		x15 = self.conv15(x15_0)
		x15 = self.bn15(x15)
		x15 = self.relu15(x15)
		x16_0 = x15
		x16 = self.conv16(x16_0)
		x16 = self.bn16(x16)
		x16 = self.relu16(x16)
		x17_0 = x16
		x17 = self.conv17(x17_0)
		x17 = self.bn17(x17)
		x17 = self.relu17(x17)
		x18_0 = x17
		x18 = self.conv18(x18_0)
		x18 = self.bn18(x18)
		x18 = self.relu18(x18)
		x19_0 = x18
		x19 = self.conv19(x19_0)
		x19 = self.bn19(x19)
		x19 = self.relu19(x19)
		x20_0 = x19
		x20 = self.conv20(x20_0)
		x20 = self.bn20(x20)
		x20 = self.relu20(x20)
		x21_0 = x20
		x21 = self.conv21(x21_0)
		x21 = self.bn21(x21)
		x21 = self.relu21(x21)

		x22_0 = torch.cat((x19, x21), dim=1)
		x22 = self.conv22(x22_0)
		x22 = self.bn22(x22)
		x22 = self.relu22(x22)
		x23_0 = torch.cat((x18, x22), dim=1)
		x23 = self.conv23(x23_0)
		x23 = self.bn23(x23)
		x13 = self.relu23(x23)
		x24_0 = torch.cat((x17, x23), dim=1)
		x24 = self.conv24(x24_0)
		x24 = self.bn24(x24)
		x24 = self.relu24(x24)
		x25_0 = torch.cat((x16, x24), dim=1)
		x25 = self.conv25(x25_0)
		x25 = self.bn25(x25)
		x25 = self.relu25(x25)
		x26_0 = torch.cat((x15, x25), dim=1)
		x26 = self.conv26(x26_0)
		x26 = self.bn26(x26)
		x26 = self.relu26(x26)
		x27_0 = torch.cat((x14, x26), dim=1)
		x27 = self.conv27(x27_0)
		x27 = self.bn27(x27)
		x27 = self.relu27(x27)
		x28_0 = torch.cat((x13, x27), dim=1)
		x28 = self.conv28(x28_0)
		x28 = self.bn28(x28)
		x28 = self.relu28(x28)
		x29_0 = torch.cat((x12, x28), dim=1)
		x29 = self.conv29(x29_0)
		x29 = self.bn29(x29)
		x29 = self.relu29(x29)
		x30_0 = torch.cat((x11, x29), dim=1)
		x30 = self.conv30(x30_0)
		x30 = self.bn30(x30)
		x30 = self.relu30(x30)

		x31_0 = torch.cat((x10, x30), dim=1)
		x31 = self.conv31(x31_0)
		x31 = self.bn31(x31)
		x31 = self.relu31(x31)
		x32_0 = torch.cat((x9, x31), dim=1)
		x32 = self.conv32(x32_0)
		x32 = self.bn32(x32)
		x32 = self.relu32(x32)
		x33_0 = torch.cat((x8, x32), dim=1)
		x33 = self.conv33(x33_0)
		x33 = self.bn33(x33)
		x33 = self.relu33(x33)
		x34_0 = torch.cat((x7, x33), dim=1)
		x34 = self.conv34(x34_0)
		x34 = self.bn34(x34)
		x34 = self.relu34(x34)
		x35_0 = torch.cat((x6, x34), dim=1)
		x35 = self.conv35(x35_0)
		x35 = self.bn35(x35)
		x35 = self.relu35(x35)
		x36_0 = torch.cat((x5, x35), dim=1)
		x36 = self.conv36(x36_0)
		x36 = self.bn36(x36)
		x36 = self.relu36(x36)
		x37_0 = torch.cat((x4, x36), dim=1)
		x37 = self.conv37(x37_0)
		x37 = self.bn37(x37)
		x37 = self.relu37(x37)
		x38_0 = torch.cat((x3, x37), dim=1)
		x38 = self.conv38(x38_0)
		x38 = self.bn38(x38)
		x38 = self.relu38(x38)
		x39_0 = torch.cat((x2, x38), dim=1)
		x39 = self.conv39(x39_0)
		x39 = self.bn39(x39)
		x39 = self.relu39(x39)
		x40_0 = torch.cat((x1, x39), dim=1)
		x40 = self.conv40(x40_0)
		x40 = self.bn40(x40)
		x40 = self.relu40(x40)
		

		out = x40 * x - x40 + 1
		out = self.clip(out)
		
		if target is not None:
			pairs = {'out': (out, target)}
			return pairs, self.exports(x, out, target)
		else:
			return self.exports(x, out, target)

	def exports(self, x, output, target):
		result = {'input': x, 'output': output}
		if target is not None:
			result['target'] = target
		return result


if __name__ == '__main__':
	model = Unet_AOD_Deep_Wide_Net()
	x = Variable(torch.ones(4, 3, 100, 100))
	y = Variable(torch.ones(4, 3, 100, 100))
	if torch.cuda.is_available():
		model.cuda()
		x = x.cuda()
		y = y.cuda()
	model.eval()

	out = model(x)
	for key, value in out.items():
		print(key + ':', value.size())

